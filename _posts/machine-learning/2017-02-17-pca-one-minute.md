---
layout: post
date: 2017-02-17 21:06
status: public
tags: 'PCA, 线性代数, 矩阵, 特征值, 变换'
title: '一分钟理解 PCA 的原理'
categories: [Machine-Learning]
---

现在我们有这样一组数据

<img src="{{ "/assets/img/machine-learning/pca.jpg" | absolute_url }}" width="400">

而 PCA 想做的事情非常简单

>  把这个看起来倾斜的数据，变换成以图中两个箭头为坐标轴

具体来说就是找到图中两个箭头所表示的向量，并以他们为基来表示其它数据。那怎么做到呢？如果把我们现有的数据为$X$, 那么我们想找的就是一个线性变换 $P$ 使得

$$
Y = PX
$$

也许直接寻找 $P$ 比较困难，那么反过来想，如果我们已经知道了 $P$ 会得到什么。

我们都知道，$X$ 的协方差矩阵可以表示为 $A = XX^T$，而$Y$的协方差矩阵为 $B = YY^T$ 。而 $X$ 和 $Y$ 最大的区别就在于 $B$ 是一个对角矩阵，因为在这组基的表示下，各个变量之间的相关系数都是 $0$，也就是$B$的非对角线元素都为 $0$. 否则它一定有哪一个维度没有转过来。


好，我们把 $B$ 展开看看

$$
B = YY^T = (PX)(PX)^T = PXX^TP^T = PAP^T
$$

仔细一看这个式子，第一个想到的词就是「相似对角化」

我们知道 $A$ 是一个实对称矩阵，一定可以分解为 $A = Q^{-1}MQ$ ,其中 $M$ 为对角矩阵, $Q$ 是正交矩阵。那么只要令 $P = Q$ , 代入就可以得到

$$
B = PAP^T = P(Q^{-1}MQ)P^T = (PQ^{-1})M(PQ^{-1})^T = M
$$

这样我们就有了求解 $P$ 的基本思路。 

至于如和进行对角化并找到 $Q$ ，只需要先求特征值和特征向量，然后构造出对应的矩阵就可以了。